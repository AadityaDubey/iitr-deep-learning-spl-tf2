{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Models and Training with TensorFlow**\n",
    "\n",
    "\n",
    "This notebook is inspired from the handson-ml2 GitHub repository by Aurélien Geron\n",
    "\n",
    "https://github.com/ageron/handson-ml2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install -U tqdm\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar Tensor of integer\n",
    "\n",
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar Tensor of Float\n",
    "\n",
    "\n",
    "tf.constant(42.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor representing matrix with two rows and three columns of floats\n",
    "\n",
    "tf.constant([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of Tensor\n",
    "\n",
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type of Tensor\n",
    "\n",
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operation - Addition\n",
    "\n",
    "t + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operation - Addition - Another way\n",
    "\n",
    "\n",
    "tf.add(t,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operation - Square\n",
    "\n",
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operation - Multiply\n",
    "\n",
    "tf.multiply(t, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operation - Square root\n",
    "\n",
    "tf.sqrt(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operation - Transpose\n",
    "\n",
    "tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operation - Matrix Multiplication\n",
    "\n",
    "tf.matmul(t, tf.transpose(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tensor Operation - Matrix Multiplication - Another way\n",
    "\n",
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From/To NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensor from NumPy array\n",
    "\n",
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensor to Numpy array\n",
    "\n",
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensor to Numpy array - Another way\n",
    "\n",
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensor from NumPy array\n",
    "\n",
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensor to Numpy array\n",
    "\n",
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conflicting Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tensors of float and integer\n",
    "\n",
    "# tf.constant(2.0) + tf.constant(40)\n",
    "\n",
    "# The above code will throw exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tensors of float and integer\n",
    "# Handling Exception\n",
    "\n",
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tensors of 32-bit and 64-bit\n",
    "# Handling Exception\n",
    "\n",
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type Casting\n",
    "# Converting 64-bit tensor to 32-bit and then adding tensors\n",
    "\n",
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf variable with two rows and three columns\n",
    "\n",
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify in place with assign()\n",
    "\n",
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update cell with assign()\n",
    "# Update cells with index (0,1) to 42.0\n",
    "\n",
    "v[0, 1].assign(42.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update cell with scatter_nd_update()\n",
    "# Update cells with index (0,0) and (1,2) to 100.0 and 200.0 respectively\n",
    "\n",
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Data Structures - Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Tensor - Byte String\n",
    "\n",
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Tensor - Unicode strings get encoded to utf-8 automatically\n",
    "\n",
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent Unicode strings using tensor of type tf.int32\n",
    "\n",
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor of string arrays\n",
    "\n",
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lists, with each being of variable length\n",
    "# Consider a speech like this, where the length may change wildly on each line\n",
    "\n",
    "speech = tf.ragged.constant(\n",
    "  [['All', 'the', 'world', 'is', 'a', 'stage'],\n",
    "  ['And', 'all', 'the', 'men', 'and', 'women', 'merely', 'players'],\n",
    "  ['They', 'have', 'their', 'exits', 'and', 'their', 'entrances']])\n",
    "\n",
    "speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speech[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speech[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more example of Ragged Tensors\n",
    "# Variable-length features, such as the set of actors in a movie.\n",
    "\n",
    "actors = tf.ragged.constant(\n",
    "  [['Matt Damon', 'Robin Williams'],\n",
    "  ['John Travolta', 'Samuel L. Jackson', 'Uma Thurman', 'Harvey Keitel', 'Bruce Willis'],\n",
    "  ['Tim Robbins', 'Morgan Freeman', 'Bob Gunton', 'William Sadler']])\n",
    "\n",
    "actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fetch_california_housing() function to load the data. \n",
    "# This dataset contains only numerical features (there is no ocean_proximity feature)\n",
    "# And there is no missing value. \n",
    "# After loading the data, we split it into a training set, a validation set, and a test set\n",
    "# And we scale all the features\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# fetch the data\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# split it into a training set, a validation set, and a test set\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# Scale all the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function - Huber Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement huber loss. Huber loss is less sensitive to outliers in data than mean squared error.\n",
    "Below is the formula of huber loss."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber loss (green) vs squared error loss (blue)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom loss function\n",
    "# Define Huber loss function\n",
    "\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the network.\n",
    "# Output layer just contains 1 neuron since we have to predict only one value\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the loss function and the optimizer to use.\n",
    "# Here we are using custom loss function\n",
    "# Measure MAE during training and evaluation\n",
    "\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading Models with Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "# Specify the custom loss function while loading the model\n",
    "\n",
    "loaded_model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\": huber_fn})\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that loss = metric * mean of sample weights (plus some floating point precision error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a streaming metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        #self.huber_fn = create_huber(threshold) # TODO: investigate why this fails\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def huber_fn(self, y_true, y_pred): # workaround\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: when running the following cell, if you get autograph warnings such as `WARNING:tensorflow:AutoGraph could not transform [...] and will run it as-is`, then please install version 0.2.2 of the gast library (e.g., by running `!pip install gast==0.2.2`), then restart the kernel and run this notebook again from the beginning (see [autograph issue #1](https://github.com/tensorflow/autograph/issues/1) for more details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",           # TODO: check PR #25956\n",
    "#                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "#                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: In TF 2.2, tf.keras adds an extra first metric in `model.metrics` at position 0 (see [TF issue #38150](https://github.com/tensorflow/tensorflow/issues/38150)). This forces us to use `model.metrics[-1]` rather than `model.metrics[0]` to access the `HuberMetric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\",        # TODO: check PR #25956\n",
    "#                                custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: In TF 2.2, tf.keras adds an extra first metric in `model.metrics` at position 0 (see [TF issue #38150](https://github.com/tensorflow/tensorflow/issues/38150)). This forces us to use `model.metrics[-1]` rather than `model.metrics[0]` to access the `HuberMetric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a layer with a different behavior during training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        # TODO: check https://github.com/tensorflow/tensorflow/issues/26260\n",
    "        #self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        #if training:\n",
    "        #    result = self.reconstruction_mean(recon_loss)\n",
    "        #    self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Python function to TensorFlow function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python function for calculating Square\n",
    "\n",
    "def square(x):\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns square for integer\n",
    "\n",
    "square(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Python Function to TensorFlow function\n",
    "\n",
    "@tf.function\n",
    "def square(x):\n",
    "    return x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns Tensor\n",
    "\n",
    "square(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Original Python function can be called with python_function attribute\n",
    "\n",
    "square.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__square(x):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('square', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "    do_return = True\n",
      "    retval_ = fscope.mark_return_value(x ** 2)\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the code generated by TensorFlow\n",
    "\n",
    "print(tf.autograph.to_code(square.python_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow computational graph is wrapped in concrete function get_concrete_function\n",
    "\n",
    "concrete_function = square.get_concrete_function(tf.constant(2.0))\n",
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing tf.where\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "condition = tf.Variable(\n",
    "    np.array([[True, False, False],[False, True, False],[True, True, True]]), dtype = tf.bool, name = 'condition'\n",
    ")\n",
    "\n",
    "x = tf.Variable(\n",
    "    np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]]), dtype = tf.float32, name = 'x'\n",
    ")\n",
    "y =tf.Variable(\n",
    "    np.array([[11, 12, 13],[14, 15, 16],[17, 18, 19]]), dtype = tf.float32, name = 'y'\n",
    ")\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "r = tf.where(condition, x, y)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum using for loop = 4999950000\n",
      "Computation time = 77.94999999999952ms\n",
      "sum using numpy = 4999950000\n",
      "Computation time = 0.5579999999998364ms\n"
     ]
    }
   ],
   "source": [
    "# Vectorized operation vs for loop\n",
    "\n",
    "\n",
    "# With for loop\n",
    "tic = time.process_time()\n",
    "total = 0\n",
    "for i in np.arange(100000):\n",
    "    total = i + total\n",
    "toc = time.process_time()\n",
    "\n",
    "print(\"sum using for loop = \"+ str(total)); \n",
    "print(\"Computation time = \" + str(1000*(toc - tic )) + \"ms\")\n",
    "\n",
    "\n",
    "# With numpy\n",
    "tic = time.process_time()\n",
    "total = np.sum(np.arange(100000))\n",
    "toc = time.process_time()\n",
    "\n",
    "print(\"sum using numpy = \"+ str(total)); \n",
    "print(\"Computation time = \" + str(1000*(toc - tic )) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
